{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8904993f",
   "metadata": {},
   "source": [
    "# Home Credit Prediction Models\n",
    "\n",
    "Finding best model to use for predicting if client will have payment difficulties or not.\n",
    "\n",
    "1. Combining and Spliting Data\n",
    "2. Models with No Feature Engineering,\n",
    "3. Models with Feature Engineering,\n",
    "4. Tuning Models with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2661833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import math\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    FunctionTransformer,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from optuna import create_study\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from IPython.display import display\n",
    "import json\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from functions import convert_days_to_years, convert_days_to_months, show_head_and_info\n",
    "from model_functions import (\n",
    "    get_generic_preprocessor,\n",
    "    feature_engineering_custom,\n",
    "    merge_by_sk_id_curr,\n",
    ")\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a7a8c",
   "metadata": {},
   "source": [
    "## 1. Combining and Spliting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aee9a2",
   "metadata": {},
   "source": [
    "### About Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca672bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_data = pd.read_csv(\"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d3d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = merge_by_sk_id_curr(application_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c832d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sk_id_curr</th>\n",
       "      <th>target</th>\n",
       "      <th>name_contract_type</th>\n",
       "      <th>code_gender</th>\n",
       "      <th>flag_own_car</th>\n",
       "      <th>flag_own_realty</th>\n",
       "      <th>cnt_children</th>\n",
       "      <th>amt_income_total</th>\n",
       "      <th>amt_credit</th>\n",
       "      <th>amt_annuity</th>\n",
       "      <th>...</th>\n",
       "      <th>name_goods_category_other</th>\n",
       "      <th>name_payment_type_other</th>\n",
       "      <th>name_portfolio_other</th>\n",
       "      <th>name_product_type_other</th>\n",
       "      <th>name_seller_industry_other</th>\n",
       "      <th>name_type_suite_other</th>\n",
       "      <th>name_yield_group_other</th>\n",
       "      <th>product_combination_other</th>\n",
       "      <th>status_other</th>\n",
       "      <th>weekday_appr_process_start_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Vehicles</td>\n",
       "      <td>XNA</td>\n",
       "      <td>POS</td>\n",
       "      <td>XNA</td>\n",
       "      <td>Auto technology</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>low_normal</td>\n",
       "      <td>POS other with interest</td>\n",
       "      <td>0</td>\n",
       "      <td>SATURDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>Cash through the bank</td>\n",
       "      <td>POS</td>\n",
       "      <td>XNA</td>\n",
       "      <td>Consumer electronics</td>\n",
       "      <td>Family</td>\n",
       "      <td>middle</td>\n",
       "      <td>POS household with interest</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SATURDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Cash through the bank</td>\n",
       "      <td>POS</td>\n",
       "      <td>XNA</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>middle</td>\n",
       "      <td>POS mobile without interest</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FRIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>Cash through the bank</td>\n",
       "      <td>Cash</td>\n",
       "      <td>x-sell</td>\n",
       "      <td>Consumer electronics</td>\n",
       "      <td>Family</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash X-Sell: middle</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SUNDAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sk_id_curr  target name_contract_type code_gender flag_own_car  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  flag_own_realty  cnt_children  amt_income_total  amt_credit  amt_annuity  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  name_goods_category_other name_payment_type_other  \\\n",
       "0  ...                   Vehicles                     XNA   \n",
       "1  ...       Consumer Electronics   Cash through the bank   \n",
       "2  ...                     Mobile   Cash through the bank   \n",
       "3  ...                        NaN                     NaN   \n",
       "4  ...                        XNA   Cash through the bank   \n",
       "\n",
       "  name_portfolio_other name_product_type_other name_seller_industry_other  \\\n",
       "0                  POS                     XNA            Auto technology   \n",
       "1                  POS                     XNA       Consumer electronics   \n",
       "2                  POS                     XNA               Connectivity   \n",
       "3                  NaN                     NaN                        NaN   \n",
       "4                 Cash                  x-sell       Consumer electronics   \n",
       "\n",
       "  name_type_suite_other  name_yield_group_other    product_combination_other  \\\n",
       "0               Unknown              low_normal      POS other with interest   \n",
       "1                Family                  middle  POS household with interest   \n",
       "2         Unaccompanied                  middle  POS mobile without interest   \n",
       "3                   NaN                     NaN                          NaN   \n",
       "4                Family                    high          Cash X-Sell: middle   \n",
       "\n",
       "   status_other  weekday_appr_process_start_other  \n",
       "0             0                          SATURDAY  \n",
       "1          <NA>                          SATURDAY  \n",
       "2          <NA>                            FRIDAY  \n",
       "3           NaN                               NaN  \n",
       "4          <NA>                            SUNDAY  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 219 entries, sk_id_curr to weekday_appr_process_start_other\n",
      "dtypes: float64(140), int64(41), object(38)\n",
      "memory usage: 513.8+ MB\n"
     ]
    }
   ],
   "source": [
    "show_head_and_info(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa92362",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb67f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.drop(columns=[\"target\"])\n",
    "y = model_df[\"target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d267f",
   "metadata": {},
   "source": [
    "## 2. On Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5a1f8",
   "metadata": {},
   "source": [
    "### 2.1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04f8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = get_generic_preprocessor(X_train, impute=True)\n",
    "preprocessor_no_impute = get_generic_preprocessor(X_train, impute=False)\n",
    "\n",
    "class_ratio = y_train.value_counts(normalize=True)\n",
    "if len(class_ratio) > 1 and class_ratio[1] > 0:\n",
    "    scale_pos_weight = class_ratio[0] / class_ratio[1]\n",
    "else:\n",
    "    scale_pos_weight = 1\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                RandomForestClassifier(random_state=42, class_weight=\"balanced\"),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"XGBoost\": Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor_no_impute),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                XGBClassifier(\n",
    "                    random_state=42,\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    use_label_encoder=False,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"Logistic Regression\": Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(random_state=42, class_weight=\"balanced\"),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"KNN\": Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", KNeighborsClassifier()),\n",
    "        ]\n",
    "    ),\n",
    "    \"LightGBM\": Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor_no_impute),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LGBMClassifier(\n",
    "                    random_state=42, scale_pos_weight=scale_pos_weight, verbose=0\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"CatBoost\": Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor_no_impute),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                CatBoostClassifier(\n",
    "                    random_seed=42, auto_class_weights=\"Balanced\", verbose=0\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45520274",
   "metadata": {},
   "source": [
    "### 2.2. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abfa724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest finished in 181.05 seconds.\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [18:00:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost finished in 16.66 seconds.\n",
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression finished in 17.88 seconds.\n",
      "\n",
      "Training KNN...\n",
      "KNN finished in 162.58 seconds.\n",
      "\n",
      "Training LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM finished in 11.94 seconds.\n",
      "\n",
      "Training CatBoost...\n",
      "CatBoost finished in 81.97 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_42a82_row0_col0 {\n",
       "  background-color: #4493c7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row0_col1 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row0_col2, #T_42a82_row2_col3, #T_42a82_row2_col4, #T_42a82_row3_col0, #T_42a82_row3_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row0_col3, #T_42a82_row0_col4, #T_42a82_row4_col0, #T_42a82_row4_col1, #T_42a82_row5_col2 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row1_col0 {\n",
       "  background-color: #0a539e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row1_col1, #T_42a82_row2_col2 {\n",
       "  background-color: #08458a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row1_col2 {\n",
       "  background-color: #083979;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row1_col3 {\n",
       "  background-color: #c3daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row1_col4 {\n",
       "  background-color: #caddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row2_col0 {\n",
       "  background-color: #0a549e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row2_col1 {\n",
       "  background-color: #083b7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row3_col2 {\n",
       "  background-color: #dce9f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row3_col3, #T_42a82_row5_col1 {\n",
       "  background-color: #083573;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row3_col4 {\n",
       "  background-color: #083674;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row4_col2 {\n",
       "  background-color: #083d7f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row4_col3 {\n",
       "  background-color: #eaf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row4_col4 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row5_col0 {\n",
       "  background-color: #083370;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_42a82_row5_col3 {\n",
       "  background-color: #aed1e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_42a82_row5_col4 {\n",
       "  background-color: #b7d4ea;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_42a82\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_42a82_level0_col0\" class=\"col_heading level0 col0\" >PR-AUC</th>\n",
       "      <th id=\"T_42a82_level0_col1\" class=\"col_heading level0 col1\" >ROC-AUC</th>\n",
       "      <th id=\"T_42a82_level0_col2\" class=\"col_heading level0 col2\" >F1-Score (Payment Difficulties)</th>\n",
       "      <th id=\"T_42a82_level0_col3\" class=\"col_heading level0 col3\" >F1-Score (Other Cases)</th>\n",
       "      <th id=\"T_42a82_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_42a82_level0_row0\" class=\"row_heading level0 row0\" >Random Forest</th>\n",
       "      <td id=\"T_42a82_row0_col0\" class=\"data row0 col0\" >0.202136</td>\n",
       "      <td id=\"T_42a82_row0_col1\" class=\"data row0 col1\" >0.723952</td>\n",
       "      <td id=\"T_42a82_row0_col2\" class=\"data row0 col2\" >0.002010</td>\n",
       "      <td id=\"T_42a82_row0_col3\" class=\"data row0 col3\" >0.957935</td>\n",
       "      <td id=\"T_42a82_row0_col4\" class=\"data row0 col4\" >0.919272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42a82_level0_row1\" class=\"row_heading level0 row1\" >XGBoost</th>\n",
       "      <td id=\"T_42a82_row1_col0\" class=\"data row1 col0\" >0.241066</td>\n",
       "      <td id=\"T_42a82_row1_col1\" class=\"data row1 col1\" >0.754734</td>\n",
       "      <td id=\"T_42a82_row1_col2\" class=\"data row1 col2\" >0.281950</td>\n",
       "      <td id=\"T_42a82_row1_col3\" class=\"data row1 col3\" >0.848090</td>\n",
       "      <td id=\"T_42a82_row1_col4\" class=\"data row1 col4\" >0.749232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42a82_level0_row2\" class=\"row_heading level0 row2\" >Logistic Regression</th>\n",
       "      <td id=\"T_42a82_row2_col0\" class=\"data row2 col0\" >0.240951</td>\n",
       "      <td id=\"T_42a82_row2_col1\" class=\"data row2 col1\" >0.761431</td>\n",
       "      <td id=\"T_42a82_row2_col2\" class=\"data row2 col2\" >0.268754</td>\n",
       "      <td id=\"T_42a82_row2_col3\" class=\"data row2 col3\" >0.809510</td>\n",
       "      <td id=\"T_42a82_row2_col4\" class=\"data row2 col4\" >0.697755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42a82_level0_row3\" class=\"row_heading level0 row3\" >KNN</th>\n",
       "      <td id=\"T_42a82_row3_col0\" class=\"data row3 col0\" >0.104049</td>\n",
       "      <td id=\"T_42a82_row3_col1\" class=\"data row3 col1\" >0.583916</td>\n",
       "      <td id=\"T_42a82_row3_col2\" class=\"data row3 col2\" >0.042109</td>\n",
       "      <td id=\"T_42a82_row3_col3\" class=\"data row3 col3\" >0.954678</td>\n",
       "      <td id=\"T_42a82_row3_col4\" class=\"data row3 col4\" >0.913451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42a82_level0_row4\" class=\"row_heading level0 row4\" >LightGBM</th>\n",
       "      <td id=\"T_42a82_row4_col0\" class=\"data row4 col0\" >0.262668</td>\n",
       "      <td id=\"T_42a82_row4_col1\" class=\"data row4 col1\" >0.769708</td>\n",
       "      <td id=\"T_42a82_row4_col2\" class=\"data row4 col2\" >0.276782</td>\n",
       "      <td id=\"T_42a82_row4_col3\" class=\"data row4 col3\" >0.819234</td>\n",
       "      <td id=\"T_42a82_row4_col4\" class=\"data row4 col4\" >0.710762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42a82_level0_row5\" class=\"row_heading level0 row5\" >CatBoost</th>\n",
       "      <td id=\"T_42a82_row5_col0\" class=\"data row5 col0\" >0.260477</td>\n",
       "      <td id=\"T_42a82_row5_col1\" class=\"data row5 col1\" >0.765673</td>\n",
       "      <td id=\"T_42a82_row5_col2\" class=\"data row5 col2\" >0.292237</td>\n",
       "      <td id=\"T_42a82_row5_col3\" class=\"data row5 col3\" >0.858083</td>\n",
       "      <td id=\"T_42a82_row5_col4\" class=\"data row5 col4\" >0.763573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea7e571550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results = {}\n",
    "print(\"Starting model training...\\n\")\n",
    "\n",
    "for model_name, model_pipeline in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    y_pred = model_pipeline.predict(X_val)\n",
    "\n",
    "    try:\n",
    "        y_pred_proba = model_pipeline.predict_proba(X_val)[:, 1]\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            decision_scores = model_pipeline.decision_function(X_val)\n",
    "            if decision_scores.ndim > 1 and decision_scores.shape[1] > 1:\n",
    "                y_pred_proba = (\n",
    "                    (decision_scores[:, 1] - decision_scores[:, 1].min())\n",
    "                    / (decision_scores[:, 1].max() - decision_scores[:, 1].min())\n",
    "                    if (decision_scores[:, 1].max() - decision_scores[:, 1].min()) != 0\n",
    "                    else np.zeros_like(y_pred, dtype=float)\n",
    "                )\n",
    "            else:\n",
    "                y_pred_proba = (\n",
    "                    (decision_scores - decision_scores.min())\n",
    "                    / (decision_scores.max() - decision_scores.min())\n",
    "                    if (decision_scores.max() - decision_scores.min()) != 0\n",
    "                    else np.zeros_like(y_pred, dtype=float)\n",
    "                )\n",
    "        except AttributeError:\n",
    "            y_pred_proba = np.zeros_like(y_pred, dtype=float)\n",
    "        except Exception:\n",
    "            y_pred_proba = np.zeros_like(y_pred, dtype=float)\n",
    "\n",
    "    pr_auc = average_precision_score(y_val, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    f1_score_1 = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "    f1_score_0 = f1_score(y_val, y_pred, pos_label=0, zero_division=0)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    model_results[model_name] = [pr_auc, roc_auc, f1_score_1, f1_score_0, accuracy]\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{model_name} finished in {elapsed:.2f} seconds.\\n\")\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    model_results,\n",
    "    index=[\n",
    "        \"PR-AUC\",\n",
    "        \"ROC-AUC\",\n",
    "        \"F1-Score (Payment Difficulties)\",\n",
    "        \"F1-Score (Other Cases)\",\n",
    "        \"Accuracy\",\n",
    "    ],\n",
    ").T\n",
    "\n",
    "try:\n",
    "    display(df_results.style.background_gradient(cmap=\"Blues\"))\n",
    "except ImportError:\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a73bd35",
   "metadata": {},
   "source": [
    "On the raw dataset, with only basic missing value handling and encoding:\n",
    "* CatBoost has second highest PR-AUC (26.05%) and highest F1-Score for payment difficulties group (29.22%).\n",
    "* LightGBM has highest PR-AUC (26.27%), but has lower F1-score (27.68%) for payment difficulties group.\n",
    "* XGBoost even if it doesn't have hight PR-AUC (24.11%), but it has high F1-score (28.20%) for payment difficulties group\n",
    "* Logistic Regression is average in all metrix.\n",
    "* KNN and Random Forest have good accuracy and F1-score other cases, but they work badly with payment difficulties group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9423f25",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be045edf",
   "metadata": {},
   "source": [
    "### 3.1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9ea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.func(X)\n",
    "\n",
    "\n",
    "feature_engineering = FeatureEngineeringTransformer(feature_engineering_custom)\n",
    "X_train_fe = feature_engineering_custom(X_train)\n",
    "\n",
    "preprocessor = get_generic_preprocessor(X_train_fe, impute=True)\n",
    "preprocessor_no_impute = get_generic_preprocessor(X_train_fe, impute=False)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": Pipeline(\n",
    "        [\n",
    "            (\"feature_engineering\", feature_engineering),\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                RandomForestClassifier(random_state=42, class_weight=\"balanced\"),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"XGBoost\": Pipeline(\n",
    "        [\n",
    "            (\"feature_engineering\", feature_engineering),\n",
    "            (\"preprocessor\", preprocessor_no_impute),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                XGBClassifier(\n",
    "                    random_state=42,\n",
    "                    scale_pos_weight=scale_pos_weight,\n",
    "                    use_label_encoder=False,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"Logistic Regression\": Pipeline(\n",
    "        [\n",
    "            (\"feature_engineering\", feature_engineering),\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    random_state=42, class_weight=\"balanced\", max_iter=1000\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"KNN\": Pipeline(\n",
    "        [\n",
    "            (\"feature_engineering\", feature_engineering),\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", KNeighborsClassifier()),\n",
    "        ]\n",
    "    ),\n",
    "    \"LightGBM\": Pipeline(\n",
    "        [\n",
    "            (\"feature_engineering\", feature_engineering),\n",
    "            (\"preprocessor\", preprocessor_no_impute),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LGBMClassifier(\n",
    "                    random_state=42, scale_pos_weight=scale_pos_weight, verbose=0\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"CatBoost\": Pipeline(\n",
    "        [\n",
    "            (\"feature_engineering\", feature_engineering),\n",
    "            (\"preprocessor\", preprocessor_no_impute),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                CatBoostClassifier(\n",
    "                    random_seed=42, auto_class_weights=\"Balanced\", verbose=0\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f31c39",
   "metadata": {},
   "source": [
    "### 3.2. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc293608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "\n",
      "Evaluating Random Forest...\n",
      "Random Forest finished in 730.90 seconds.\n",
      "\n",
      "Evaluating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [18:18:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [18:18:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost finished in 85.21 seconds.\n",
      "\n",
      "Evaluating Logistic Regression...\n",
      "Logistic Regression finished in 190.23 seconds.\n",
      "\n",
      "Evaluating KNN...\n",
      "KNN finished in 584.56 seconds.\n",
      "\n",
      "Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM finished in 55.32 seconds.\n",
      "\n",
      "Evaluating CatBoost...\n",
      "CatBoost finished in 416.36 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_68b0d_row0_col0 {\n",
       "  background-color: #3d8dc4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row0_col1 {\n",
       "  background-color: #1c6bb0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row0_col2, #T_68b0d_row2_col3, #T_68b0d_row2_col4, #T_68b0d_row3_col0, #T_68b0d_row3_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row0_col3, #T_68b0d_row0_col4, #T_68b0d_row4_col0, #T_68b0d_row4_col1, #T_68b0d_row5_col2 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row1_col0 {\n",
       "  background-color: #09529d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row1_col1 {\n",
       "  background-color: #084990;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row1_col2 {\n",
       "  background-color: #083a7a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row1_col3 {\n",
       "  background-color: #bcd7eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row1_col4 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row2_col0 {\n",
       "  background-color: #08458a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row2_col1, #T_68b0d_row5_col1 {\n",
       "  background-color: #083776;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row2_col2 {\n",
       "  background-color: #084387;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row3_col2 {\n",
       "  background-color: #deebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row3_col3 {\n",
       "  background-color: #083471;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row3_col4 {\n",
       "  background-color: #083573;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row4_col2 {\n",
       "  background-color: #083d7f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row4_col3 {\n",
       "  background-color: #ecf4fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row4_col4 {\n",
       "  background-color: #edf4fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row5_col0 {\n",
       "  background-color: #08326e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_68b0d_row5_col3 {\n",
       "  background-color: #aacfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_68b0d_row5_col4 {\n",
       "  background-color: #b4d3e9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_68b0d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68b0d_level0_col0\" class=\"col_heading level0 col0\" >PR-AUC</th>\n",
       "      <th id=\"T_68b0d_level0_col1\" class=\"col_heading level0 col1\" >ROC-AUC</th>\n",
       "      <th id=\"T_68b0d_level0_col2\" class=\"col_heading level0 col2\" >F1-Score (Payment Difficulties)</th>\n",
       "      <th id=\"T_68b0d_level0_col3\" class=\"col_heading level0 col3\" >F1-Score (Other Cases)</th>\n",
       "      <th id=\"T_68b0d_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68b0d_level0_row0\" class=\"row_heading level0 row0\" >Random Forest</th>\n",
       "      <td id=\"T_68b0d_row0_col0\" class=\"data row0 col0\" >0.197178</td>\n",
       "      <td id=\"T_68b0d_row0_col1\" class=\"data row0 col1\" >0.723280</td>\n",
       "      <td id=\"T_68b0d_row0_col2\" class=\"data row0 col2\" >0.004308</td>\n",
       "      <td id=\"T_68b0d_row0_col3\" class=\"data row0 col3\" >0.957903</td>\n",
       "      <td id=\"T_68b0d_row0_col4\" class=\"data row0 col4\" >0.919222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68b0d_level0_row1\" class=\"row_heading level0 row1\" >XGBoost</th>\n",
       "      <td id=\"T_68b0d_row1_col0\" class=\"data row1 col0\" >0.230301</td>\n",
       "      <td id=\"T_68b0d_row1_col1\" class=\"data row1 col1\" >0.747671</td>\n",
       "      <td id=\"T_68b0d_row1_col2\" class=\"data row1 col2\" >0.279228</td>\n",
       "      <td id=\"T_68b0d_row1_col3\" class=\"data row1 col3\" >0.853182</td>\n",
       "      <td id=\"T_68b0d_row1_col4\" class=\"data row1 col4\" >0.756061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68b0d_level0_row2\" class=\"row_heading level0 row2\" >Logistic Regression</th>\n",
       "      <td id=\"T_68b0d_row2_col0\" class=\"data row2 col0\" >0.237508</td>\n",
       "      <td id=\"T_68b0d_row2_col1\" class=\"data row2 col1\" >0.760178</td>\n",
       "      <td id=\"T_68b0d_row2_col2\" class=\"data row2 col2\" >0.270091</td>\n",
       "      <td id=\"T_68b0d_row2_col3\" class=\"data row2 col3\" >0.811622</td>\n",
       "      <td id=\"T_68b0d_row2_col4\" class=\"data row2 col4\" >0.700534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68b0d_level0_row3\" class=\"row_heading level0 row3\" >KNN</th>\n",
       "      <td id=\"T_68b0d_row3_col0\" class=\"data row3 col0\" >0.103448</td>\n",
       "      <td id=\"T_68b0d_row3_col1\" class=\"data row3 col1\" >0.578782</td>\n",
       "      <td id=\"T_68b0d_row3_col2\" class=\"data row3 col2\" >0.041228</td>\n",
       "      <td id=\"T_68b0d_row3_col3\" class=\"data row3 col3\" >0.955076</td>\n",
       "      <td id=\"T_68b0d_row3_col4\" class=\"data row3 col4\" >0.914174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68b0d_level0_row4\" class=\"row_heading level0 row4\" >LightGBM</th>\n",
       "      <td id=\"T_68b0d_row4_col0\" class=\"data row4 col0\" >0.249079</td>\n",
       "      <td id=\"T_68b0d_row4_col1\" class=\"data row4 col1\" >0.765628</td>\n",
       "      <td id=\"T_68b0d_row4_col2\" class=\"data row4 col2\" >0.275926</td>\n",
       "      <td id=\"T_68b0d_row4_col3\" class=\"data row4 col3\" >0.820076</td>\n",
       "      <td id=\"T_68b0d_row4_col4\" class=\"data row4 col4\" >0.711774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68b0d_level0_row5\" class=\"row_heading level0 row5\" >CatBoost</th>\n",
       "      <td id=\"T_68b0d_row5_col0\" class=\"data row5 col0\" >0.247909</td>\n",
       "      <td id=\"T_68b0d_row5_col1\" class=\"data row5 col1\" >0.760456</td>\n",
       "      <td id=\"T_68b0d_row5_col2\" class=\"data row5 col2\" >0.291376</td>\n",
       "      <td id=\"T_68b0d_row5_col3\" class=\"data row5 col3\" >0.861275</td>\n",
       "      <td id=\"T_68b0d_row5_col4\" class=\"data row5 col4\" >0.767975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea0009faa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model_results = {}\n",
    "\n",
    "print(\"Starting model training...\\n\")\n",
    "\n",
    "for model_name, model_pipeline in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    pr_aucs, roc_aucs = [], []\n",
    "    f1_1s, f1_0s = [], []\n",
    "    accuracies = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model_pipeline.fit(X_tr, y_tr)\n",
    "        y_pred = model_pipeline.predict(X_va)\n",
    "\n",
    "        try:\n",
    "            y_pred_proba = model_pipeline.predict_proba(X_va)[:, 1]\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                decision_scores = model_pipeline.decision_function(X_va)\n",
    "                if decision_scores.ndim > 1 and decision_scores.shape[1] > 1:\n",
    "                    y_pred_proba = (\n",
    "                        (decision_scores[:, 1] - decision_scores[:, 1].min())\n",
    "                        / (decision_scores[:, 1].max() - decision_scores[:, 1].min())\n",
    "                        if (decision_scores[:, 1].max() - decision_scores[:, 1].min())\n",
    "                        != 0\n",
    "                        else np.zeros_like(y_pred, dtype=float)\n",
    "                    )\n",
    "                else:\n",
    "                    y_pred_proba = (\n",
    "                        (decision_scores - decision_scores.min())\n",
    "                        / (decision_scores.max() - decision_scores.min())\n",
    "                        if (decision_scores.max() - decision_scores.min()) != 0\n",
    "                        else np.zeros_like(y_pred, dtype=float)\n",
    "                    )\n",
    "            except Exception:\n",
    "                y_pred_proba = np.zeros_like(y_pred, dtype=float)\n",
    "\n",
    "        pr_aucs.append(average_precision_score(y_va, y_pred_proba))\n",
    "        roc_aucs.append(roc_auc_score(y_va, y_pred_proba))\n",
    "        f1_1s.append(f1_score(y_va, y_pred, pos_label=1, zero_division=0))\n",
    "        f1_0s.append(f1_score(y_va, y_pred, pos_label=0, zero_division=0))\n",
    "        accuracies.append(accuracy_score(y_va, y_pred))\n",
    "\n",
    "    model_results[model_name] = [\n",
    "        np.mean(pr_aucs),\n",
    "        np.mean(roc_aucs),\n",
    "        np.mean(f1_1s),\n",
    "        np.mean(f1_0s),\n",
    "        np.mean(accuracies),\n",
    "    ]\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{model_name} finished in {elapsed:.2f} seconds.\\n\")\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    model_results,\n",
    "    index=[\n",
    "        \"PR-AUC\",\n",
    "        \"ROC-AUC\",\n",
    "        \"F1-Score (Payment Difficulties)\",\n",
    "        \"F1-Score (Other Cases)\",\n",
    "        \"Accuracy\",\n",
    "    ],\n",
    ").T\n",
    "\n",
    "try:\n",
    "    display(df_results.style.background_gradient(cmap=\"Blues\"))\n",
    "except ImportError:\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c521f",
   "metadata": {},
   "source": [
    "After applying feature engineering:\n",
    "* LightGBM has highest PR-AUC (24.91%) but a bit lower F1-score for payment difficulties (27.59%).\n",
    "* CatBoost has slightly lower PR-AUC (24.79%) and highest F1-score for payment difficulties (29.14%).\n",
    "* XGBoost has second highest F1-score for payment difficulties (27.92%), but have low PR-AUC (23.03%).\n",
    "* Logistic Regression is average as it was before.\n",
    "* KNN and Random Forest were preforming good with accuracy and F1-score for other cases group.\n",
    "\n",
    "Since KNN and Random Forest perform poorly overall, and Logistic Regression consistently underperforms more advanced models across all key metrics, we exclude them from further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805eafac",
   "metadata": {},
   "source": [
    "## 4. Tuning Models with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314cfb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_model_results = {}\n",
    "\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\": 0,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 1, 10),\n",
    "    }\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        model = XGBClassifier(**params)\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"feature_engineering\", feature_engineering),\n",
    "                (\"preprocessor\", preprocessor_no_impute),\n",
    "                (\"classifier\", model),\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "        preds = pipeline.predict_proba(X_va)[:, 1]\n",
    "        scores.append(average_precision_score(y_va, preds))\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 127),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"objective\": \"binary\",\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(**params)\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"feature_engineering\", feature_engineering),\n",
    "                (\"preprocessor\", preprocessor_no_impute),\n",
    "                (\"classifier\", model),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        preds = pipeline.predict_proba(X_va)[:, 1]\n",
    "        score = average_precision_score(y_va, preds)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 5.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 128),\n",
    "        \"verbose\": 0,\n",
    "        \"auto_class_weights\": \"Balanced\",\n",
    "        \"random_seed\": 42,\n",
    "        \"task_type\": \"CPU\",\n",
    "    }\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        model = CatBoostClassifier(**params)\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"feature_engineering\", feature_engineering),\n",
    "                (\"preprocessor\", preprocessor_no_impute),\n",
    "                (\"classifier\", model),\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "        preds = pipeline.predict_proba(X_va)[:, 1]\n",
    "        scores.append(average_precision_score(y_va, preds))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b8eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:39:15,449] A new study created in memory with name: XGBoost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:40:49,876] Trial 0 finished with value: 0.2476445867439113 and parameters: {'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 138, 'learning_rate': 0.0607498486754422, 'subsample': 0.7527716944671111, 'colsample_bytree': 0.9942358271807217, 'max_delta_step': 2}. Best is trial 0 with value: 0.2476445867439113.\n",
      "[I 2025-06-10 18:42:23,145] Trial 1 finished with value: 0.24513600542459651 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 122, 'learning_rate': 0.07446610669693111, 'subsample': 0.7222485865230469, 'colsample_bytree': 0.7364086001941689, 'max_delta_step': 5}. Best is trial 0 with value: 0.2476445867439113.\n",
      "[I 2025-06-10 18:44:01,905] Trial 2 finished with value: 0.24977466328786316 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 190, 'learning_rate': 0.05433413346104099, 'subsample': 0.7035796161205256, 'colsample_bytree': 0.9933076172423544, 'max_delta_step': 1}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:45:26,007] Trial 3 finished with value: 0.23773502246887168 and parameters: {'max_depth': 4, 'min_child_weight': 10, 'n_estimators': 132, 'learning_rate': 0.03950667004520791, 'subsample': 0.9465362373800934, 'colsample_bytree': 0.9203930504258971, 'max_delta_step': 3}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:46:51,989] Trial 4 finished with value: 0.22603801199023427 and parameters: {'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 136, 'learning_rate': 0.023448531492497874, 'subsample': 0.9484954433319054, 'colsample_bytree': 0.7561711401026954, 'max_delta_step': 6}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:48:49,404] Trial 5 finished with value: 0.23107638313047807 and parameters: {'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 255, 'learning_rate': 0.014564013507580352, 'subsample': 0.824481767981565, 'colsample_bytree': 0.7687685211941465, 'max_delta_step': 8}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:50:30,682] Trial 6 finished with value: 0.2397966967060187 and parameters: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 104, 'learning_rate': 0.039174198706131945, 'subsample': 0.8598059231392869, 'colsample_bytree': 0.907546889870383, 'max_delta_step': 4}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:52:05,992] Trial 7 finished with value: 0.2342348233366464 and parameters: {'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 107, 'learning_rate': 0.03148537425176052, 'subsample': 0.7083658562004447, 'colsample_bytree': 0.9356321666233939, 'max_delta_step': 8}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:53:40,104] Trial 8 finished with value: 0.22234543903854762 and parameters: {'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 131, 'learning_rate': 0.020618549568928488, 'subsample': 0.9118665641938896, 'colsample_bytree': 0.9046310048301464, 'max_delta_step': 7}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:56:04,646] Trial 9 finished with value: 0.24871834982618238 and parameters: {'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 261, 'learning_rate': 0.026395131903796682, 'subsample': 0.782327443640923, 'colsample_bytree': 0.865265967338078, 'max_delta_step': 5}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 18:58:26,654] Trial 10 finished with value: 0.24055101992475678 and parameters: {'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 208, 'learning_rate': 0.08628259216701499, 'subsample': 0.814237400328553, 'colsample_bytree': 0.9916282604785419, 'max_delta_step': 1}. Best is trial 2 with value: 0.24977466328786316.\n",
      "[I 2025-06-10 19:00:41,146] Trial 11 finished with value: 0.2518751282284547 and parameters: {'max_depth': 5, 'min_child_weight': 9, 'n_estimators': 298, 'learning_rate': 0.05494632408551248, 'subsample': 0.7789586683847944, 'colsample_bytree': 0.8329436505311331, 'max_delta_step': 10}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:02:53,828] Trial 12 finished with value: 0.25163555795699766 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 294, 'learning_rate': 0.0534486426461888, 'subsample': 0.7639437878507438, 'colsample_bytree': 0.8210816660214286, 'max_delta_step': 10}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:05:06,970] Trial 13 finished with value: 0.2514933772903524 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 300, 'learning_rate': 0.050849361692571975, 'subsample': 0.7671267735846393, 'colsample_bytree': 0.8080154892083231, 'max_delta_step': 10}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:07:15,323] Trial 14 finished with value: 0.24967570526715094 and parameters: {'max_depth': 5, 'min_child_weight': 9, 'n_estimators': 298, 'learning_rate': 0.09987897969373777, 'subsample': 0.8751230356415971, 'colsample_bytree': 0.8213386684780181, 'max_delta_step': 10}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:09:44,029] Trial 15 finished with value: 0.2500212741862759 and parameters: {'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 265, 'learning_rate': 0.04117239727921477, 'subsample': 0.8013973444491586, 'colsample_bytree': 0.8627290575058223, 'max_delta_step': 9}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:11:31,931] Trial 16 finished with value: 0.25067601200108597 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 230, 'learning_rate': 0.06675891360363921, 'subsample': 0.7485443697919592, 'colsample_bytree': 0.7064653590721108, 'max_delta_step': 9}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:14:01,638] Trial 17 finished with value: 0.2473142135474391 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 276, 'learning_rate': 0.0470884700554609, 'subsample': 0.8296074745608432, 'colsample_bytree': 0.802797792701651, 'max_delta_step': 10}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:16:15,504] Trial 18 finished with value: 0.23012479274188288 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 236, 'learning_rate': 0.012061398992279508, 'subsample': 0.8925367963254989, 'colsample_bytree': 0.8337151900410199, 'max_delta_step': 8}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:18:07,782] Trial 19 finished with value: 0.2487527474716173 and parameters: {'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 181, 'learning_rate': 0.06960416045019564, 'subsample': 0.9974725018013679, 'colsample_bytree': 0.7766977374847887, 'max_delta_step': 7}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:21:05,362] Trial 20 finished with value: 0.24621851590755778 and parameters: {'max_depth': 8, 'min_child_weight': 9, 'n_estimators': 286, 'learning_rate': 0.03381922990588997, 'subsample': 0.780306365820021, 'colsample_bytree': 0.8776402653573052, 'max_delta_step': 9}. Best is trial 11 with value: 0.2518751282284547.\n",
      "[I 2025-06-10 19:23:07,961] Trial 21 finished with value: 0.25248494337515437 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 298, 'learning_rate': 0.05113596608549376, 'subsample': 0.7482944515367064, 'colsample_bytree': 0.8021429739691673, 'max_delta_step': 10}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:25:05,056] Trial 22 finished with value: 0.2518176790317644 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 286, 'learning_rate': 0.0575548644165529, 'subsample': 0.7350999408805693, 'colsample_bytree': 0.792676396227312, 'max_delta_step': 10}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:26:58,519] Trial 23 finished with value: 0.24733024626220407 and parameters: {'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 242, 'learning_rate': 0.07951887207352441, 'subsample': 0.739736433133536, 'colsample_bytree': 0.7848609780968299, 'max_delta_step': 9}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:28:47,200] Trial 24 finished with value: 0.2498441792995353 and parameters: {'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 276, 'learning_rate': 0.044915550670667825, 'subsample': 0.7241850849118113, 'colsample_bytree': 0.8446637583398299, 'max_delta_step': 7}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:30:20,429] Trial 25 finished with value: 0.24888569555105108 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 165, 'learning_rate': 0.05785666682995728, 'subsample': 0.7993535918988267, 'colsample_bytree': 0.7314570223150514, 'max_delta_step': 10}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:32:09,251] Trial 26 finished with value: 0.24654532688070335 and parameters: {'max_depth': 5, 'min_child_weight': 8, 'n_estimators': 219, 'learning_rate': 0.03236752495170816, 'subsample': 0.7345992455539329, 'colsample_bytree': 0.7914370528464635, 'max_delta_step': 8}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:33:57,002] Trial 27 finished with value: 0.2516685524700466 and parameters: {'max_depth': 4, 'min_child_weight': 6, 'n_estimators': 279, 'learning_rate': 0.09781231163738735, 'subsample': 0.7825728211330243, 'colsample_bytree': 0.7508546167998372, 'max_delta_step': 9}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:35:56,611] Trial 28 finished with value: 0.24981290355415667 and parameters: {'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 254, 'learning_rate': 0.06276741224168259, 'subsample': 0.8443598779821785, 'colsample_bytree': 0.883357506603351, 'max_delta_step': 6}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:37:59,382] Trial 29 finished with value: 0.2489100521745816 and parameters: {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 269, 'learning_rate': 0.06068038554324659, 'subsample': 0.7541544275957914, 'colsample_bytree': 0.8369253152053838, 'max_delta_step': 10}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:39:54,657] Trial 30 finished with value: 0.25163628918089753 and parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 286, 'learning_rate': 0.08416987192161333, 'subsample': 0.7964273802784029, 'colsample_bytree': 0.8021591331731347, 'max_delta_step': 9}. Best is trial 21 with value: 0.25248494337515437.\n",
      "[I 2025-06-10 19:41:41,989] Trial 31 finished with value: 0.2512454120956272 and parameters: {'max_depth': 4, 'min_child_weight': 6, 'n_estimators': 287, 'learning_rate': 0.09393133243160014, 'subsample': 0.7758016384102844, 'colsample_bytree': 0.754071853661111, 'max_delta_step': 9}. Best is trial 21 with value: 0.25248494337515437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: No improvement in 10 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 19:43:47,087] A new study created in memory with name: LightGBM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost finished in 3871.48 seconds.\n",
      "\n",
      "Best Parameters: {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 298, 'learning_rate': 0.05113596608549376, 'subsample': 0.7482944515367064, 'colsample_bytree': 0.8021429739691673, 'max_delta_step': 10}\n",
      "Best Average Precision Score (Optuna): 0.25248494337515437\n",
      "\n",
      "Processing LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:44:43,431] Trial 0 finished with value: 0.22249776645800728 and parameters: {'max_depth': 7, 'n_estimators': 124, 'learning_rate': 0.013072267682324395, 'num_leaves': 43, 'min_child_samples': 47, 'subsample': 0.7813628108607398, 'colsample_bytree': 0.8303136462424089}. Best is trial 0 with value: 0.22249776645800728.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:45:29,812] Trial 1 finished with value: 0.24708527159676477 and parameters: {'max_depth': 4, 'n_estimators': 149, 'learning_rate': 0.06036795251448346, 'num_leaves': 79, 'min_child_samples': 32, 'subsample': 0.7095200168074494, 'colsample_bytree': 0.7583972913629193}. Best is trial 1 with value: 0.24708527159676477.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:46:23,937] Trial 2 finished with value: 0.2487148130341542 and parameters: {'max_depth': 5, 'n_estimators': 201, 'learning_rate': 0.061037196628398974, 'num_leaves': 120, 'min_child_samples': 10, 'subsample': 0.7546092611624005, 'colsample_bytree': 0.8904115901964113}. Best is trial 2 with value: 0.2487148130341542.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:47:16,993] Trial 3 finished with value: 0.24542724764651574 and parameters: {'max_depth': 6, 'n_estimators': 158, 'learning_rate': 0.08526538889958385, 'num_leaves': 74, 'min_child_samples': 16, 'subsample': 0.785581789415736, 'colsample_bytree': 0.8538411875805672}. Best is trial 2 with value: 0.2487148130341542.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:48:28,063] Trial 4 finished with value: 0.24499761588248697 and parameters: {'max_depth': 7, 'n_estimators': 234, 'learning_rate': 0.024136725319465188, 'num_leaves': 100, 'min_child_samples': 10, 'subsample': 0.7433650105718239, 'colsample_bytree': 0.7012312695020382}. Best is trial 2 with value: 0.2487148130341542.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:49:19,300] Trial 5 finished with value: 0.2186749273788784 and parameters: {'max_depth': 4, 'n_estimators': 113, 'learning_rate': 0.017994240385392397, 'num_leaves': 94, 'min_child_samples': 14, 'subsample': 0.7298571810694098, 'colsample_bytree': 0.9578403756697524}. Best is trial 2 with value: 0.2487148130341542.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:50:18,295] Trial 6 finished with value: 0.2502215587308644 and parameters: {'max_depth': 6, 'n_estimators': 146, 'learning_rate': 0.06854658462312682, 'num_leaves': 36, 'min_child_samples': 49, 'subsample': 0.9551128155998938, 'colsample_bytree': 0.8916958625383079}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:51:15,508] Trial 7 finished with value: 0.24632880596729576 and parameters: {'max_depth': 5, 'n_estimators': 150, 'learning_rate': 0.04595437180919039, 'num_leaves': 127, 'min_child_samples': 17, 'subsample': 0.8765930643244924, 'colsample_bytree': 0.9840678422997333}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:52:11,800] Trial 8 finished with value: 0.24723805091859768 and parameters: {'max_depth': 4, 'n_estimators': 226, 'learning_rate': 0.04198917644134557, 'num_leaves': 111, 'min_child_samples': 11, 'subsample': 0.7684447924903179, 'colsample_bytree': 0.7998349724060675}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:53:18,099] Trial 9 finished with value: 0.23825800599483574 and parameters: {'max_depth': 5, 'n_estimators': 260, 'learning_rate': 0.015378131872382702, 'num_leaves': 48, 'min_child_samples': 25, 'subsample': 0.9217993658895071, 'colsample_bytree': 0.9886019636685555}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:54:24,024] Trial 10 finished with value: 0.24619136592407975 and parameters: {'max_depth': 8, 'n_estimators': 299, 'learning_rate': 0.09864152789909104, 'num_leaves': 33, 'min_child_samples': 50, 'subsample': 0.9994906142326971, 'colsample_bytree': 0.9137753687921987}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:55:22,481] Trial 11 finished with value: 0.2478024898409663 and parameters: {'max_depth': 6, 'n_estimators': 196, 'learning_rate': 0.0628434874254891, 'num_leaves': 64, 'min_child_samples': 38, 'subsample': 0.9949492008850268, 'colsample_bytree': 0.8956063645630257}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:56:18,244] Trial 12 finished with value: 0.24380430576068682 and parameters: {'max_depth': 5, 'n_estimators': 188, 'learning_rate': 0.030158394673922277, 'num_leaves': 59, 'min_child_samples': 41, 'subsample': 0.8452730994822558, 'colsample_bytree': 0.8875094767525284}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:57:20,925] Trial 13 finished with value: 0.2434403533564733 and parameters: {'max_depth': 7, 'n_estimators': 176, 'learning_rate': 0.06649688914885339, 'num_leaves': 126, 'min_child_samples': 23, 'subsample': 0.9148434220497165, 'colsample_bytree': 0.9350822558964826}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:58:22,349] Trial 14 finished with value: 0.249249829885472 and parameters: {'max_depth': 6, 'n_estimators': 220, 'learning_rate': 0.04249840282300499, 'num_leaves': 94, 'min_child_samples': 32, 'subsample': 0.8211945382418727, 'colsample_bytree': 0.8532848798512901}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 19:59:24,964] Trial 15 finished with value: 0.24929860046501204 and parameters: {'max_depth': 6, 'n_estimators': 229, 'learning_rate': 0.04056786936223145, 'num_leaves': 91, 'min_child_samples': 35, 'subsample': 0.8272704980202586, 'colsample_bytree': 0.8271535386710783}. Best is trial 6 with value: 0.2502215587308644.\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 20:00:43,488] Trial 16 finished with value: 0.24934415831657325 and parameters: {'max_depth': 8, 'n_estimators': 260, 'learning_rate': 0.028583602808228133, 'num_leaves': 86, 'min_child_samples': 42, 'subsample': 0.9376868277985126, 'colsample_bytree': 0.7652667278071484}. Best is trial 6 with value: 0.2502215587308644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: No improvement in 10 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\japer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-06-10 20:01:41,939] A new study created in memory with name: CatBoost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM finished in 1074.66 seconds.\n",
      "\n",
      "Best Parameters: {'max_depth': 6, 'n_estimators': 146, 'learning_rate': 0.06854658462312682, 'num_leaves': 36, 'min_child_samples': 49, 'subsample': 0.9551128155998938, 'colsample_bytree': 0.8916958625383079}\n",
      "Best Average Precision Score (Optuna): 0.2502215587308644\n",
      "\n",
      "Processing CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 20:04:33,443] Trial 0 finished with value: 0.24045864012948814 and parameters: {'depth': 6, 'iterations': 120, 'learning_rate': 0.09047555267706704, 'l2_leaf_reg': 3.455872424639031, 'border_count': 58}. Best is trial 0 with value: 0.24045864012948814.\n",
      "[I 2025-06-10 20:07:23,166] Trial 1 finished with value: 0.22863329568438334 and parameters: {'depth': 5, 'iterations': 122, 'learning_rate': 0.03757553545539814, 'l2_leaf_reg': 3.6393102262301174, 'border_count': 120}. Best is trial 0 with value: 0.24045864012948814.\n",
      "[I 2025-06-10 20:10:57,039] Trial 2 finished with value: 0.2294881593345937 and parameters: {'depth': 5, 'iterations': 294, 'learning_rate': 0.017303083147985465, 'l2_leaf_reg': 1.5313370020107224, 'border_count': 125}. Best is trial 0 with value: 0.24045864012948814.\n",
      "[I 2025-06-10 20:14:08,848] Trial 3 finished with value: 0.21256932579551954 and parameters: {'depth': 6, 'iterations': 152, 'learning_rate': 0.010787294966406421, 'l2_leaf_reg': 2.570020666557176, 'border_count': 75}. Best is trial 0 with value: 0.24045864012948814.\n",
      "[I 2025-06-10 20:17:29,417] Trial 4 finished with value: 0.22480560977056158 and parameters: {'depth': 6, 'iterations': 228, 'learning_rate': 0.013684420062168053, 'l2_leaf_reg': 4.158019306304789, 'border_count': 47}. Best is trial 0 with value: 0.24045864012948814.\n",
      "[I 2025-06-10 20:20:28,569] Trial 5 finished with value: 0.24532065200256575 and parameters: {'depth': 4, 'iterations': 197, 'learning_rate': 0.09635281352739967, 'l2_leaf_reg': 2.7118512519508147, 'border_count': 95}. Best is trial 5 with value: 0.24532065200256575.\n",
      "[I 2025-06-10 20:23:23,080] Trial 6 finished with value: 0.2426166880169506 and parameters: {'depth': 6, 'iterations': 128, 'learning_rate': 0.09874029358297277, 'l2_leaf_reg': 1.5973617674583456, 'border_count': 81}. Best is trial 5 with value: 0.24532065200256575.\n",
      "[I 2025-06-10 20:26:24,902] Trial 7 finished with value: 0.24188487473020617 and parameters: {'depth': 6, 'iterations': 158, 'learning_rate': 0.0694331105566854, 'l2_leaf_reg': 2.355681363107146, 'border_count': 66}. Best is trial 5 with value: 0.24532065200256575.\n",
      "[I 2025-06-10 20:29:34,150] Trial 8 finished with value: 0.22006821649917394 and parameters: {'depth': 6, 'iterations': 181, 'learning_rate': 0.013565512393761772, 'l2_leaf_reg': 1.744461665350713, 'border_count': 71}. Best is trial 5 with value: 0.24532065200256575.\n",
      "[I 2025-06-10 20:33:17,968] Trial 9 finished with value: 0.24392102529510978 and parameters: {'depth': 8, 'iterations': 248, 'learning_rate': 0.0467395345467564, 'l2_leaf_reg': 4.316746075016665, 'border_count': 119}. Best is trial 5 with value: 0.24532065200256575.\n",
      "[I 2025-06-10 20:36:24,548] Trial 10 finished with value: 0.22778276482920784 and parameters: {'depth': 4, 'iterations': 222, 'learning_rate': 0.024769801782739603, 'l2_leaf_reg': 2.760662192019991, 'border_count': 97}. Best is trial 5 with value: 0.24532065200256575.\n",
      "[I 2025-06-10 20:40:09,987] Trial 11 finished with value: 0.24550655060043453 and parameters: {'depth': 8, 'iterations': 257, 'learning_rate': 0.05017550456569081, 'l2_leaf_reg': 4.8453495869518814, 'border_count': 104}. Best is trial 11 with value: 0.24550655060043453.\n",
      "[I 2025-06-10 20:44:01,348] Trial 12 finished with value: 0.24710404757733065 and parameters: {'depth': 8, 'iterations': 283, 'learning_rate': 0.05666313571333711, 'l2_leaf_reg': 4.796138934738892, 'border_count': 98}. Best is trial 12 with value: 0.24710404757733065.\n",
      "[I 2025-06-10 20:47:59,962] Trial 13 finished with value: 0.24794666818009162 and parameters: {'depth': 8, 'iterations': 298, 'learning_rate': 0.05338846541237038, 'l2_leaf_reg': 4.932894610704404, 'border_count': 102}. Best is trial 13 with value: 0.24794666818009162.\n",
      "[I 2025-06-10 20:51:56,151] Trial 14 finished with value: 0.24880792023219683 and parameters: {'depth': 8, 'iterations': 293, 'learning_rate': 0.05978909173745249, 'l2_leaf_reg': 4.9601522572093435, 'border_count': 108}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 20:55:42,122] Trial 15 finished with value: 0.24162682175264144 and parameters: {'depth': 7, 'iterations': 300, 'learning_rate': 0.03007940872323621, 'l2_leaf_reg': 4.9875154020377375, 'border_count': 110}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 20:59:16,103] Trial 16 finished with value: 0.2477491690864732 and parameters: {'depth': 7, 'iterations': 268, 'learning_rate': 0.06460663016930053, 'l2_leaf_reg': 4.2501573247078515, 'border_count': 81}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 21:02:53,710] Trial 17 finished with value: 0.24299985890635895 and parameters: {'depth': 7, 'iterations': 275, 'learning_rate': 0.04012138452984833, 'l2_leaf_reg': 3.6493413932090126, 'border_count': 89}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 21:06:33,222] Trial 18 finished with value: 0.23755611198585297 and parameters: {'depth': 8, 'iterations': 236, 'learning_rate': 0.024854967166674496, 'l2_leaf_reg': 1.09493677490316, 'border_count': 109}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 21:09:50,737] Trial 19 finished with value: 0.2460611967262642 and parameters: {'depth': 7, 'iterations': 214, 'learning_rate': 0.07043138938698397, 'l2_leaf_reg': 4.543229896797647, 'border_count': 32}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 21:13:41,551] Trial 20 finished with value: 0.24154312705640013 and parameters: {'depth': 8, 'iterations': 253, 'learning_rate': 0.03420646546885292, 'l2_leaf_reg': 3.288880738092568, 'border_count': 113}. Best is trial 14 with value: 0.24880792023219683.\n",
      "[I 2025-06-10 21:17:15,157] Trial 21 finished with value: 0.24887429840550784 and parameters: {'depth': 7, 'iterations': 270, 'learning_rate': 0.06799109639257593, 'l2_leaf_reg': 4.005653310980731, 'border_count': 85}. Best is trial 21 with value: 0.24887429840550784.\n",
      "[I 2025-06-10 21:20:52,138] Trial 22 finished with value: 0.24930671025389906 and parameters: {'depth': 7, 'iterations': 279, 'learning_rate': 0.07247427940661931, 'l2_leaf_reg': 4.078321836263899, 'border_count': 87}. Best is trial 22 with value: 0.24930671025389906.\n",
      "[I 2025-06-10 21:24:29,703] Trial 23 finished with value: 0.2501443568602153 and parameters: {'depth': 7, 'iterations': 276, 'learning_rate': 0.07134032829004856, 'l2_leaf_reg': 3.9140870405737243, 'border_count': 88}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:28:02,516] Trial 24 finished with value: 0.24921726945101536 and parameters: {'depth': 7, 'iterations': 272, 'learning_rate': 0.0766447042638466, 'l2_leaf_reg': 4.009797699520725, 'border_count': 89}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:31:26,312] Trial 25 finished with value: 0.2483948582200918 and parameters: {'depth': 7, 'iterations': 242, 'learning_rate': 0.07469748409017515, 'l2_leaf_reg': 3.8733072484436826, 'border_count': 90}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:34:52,901] Trial 26 finished with value: 0.24925698630596718 and parameters: {'depth': 7, 'iterations': 263, 'learning_rate': 0.08186409281248046, 'l2_leaf_reg': 3.1306992114216623, 'border_count': 64}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:38:07,916] Trial 27 finished with value: 0.24846943153757817 and parameters: {'depth': 7, 'iterations': 202, 'learning_rate': 0.08669553996416163, 'l2_leaf_reg': 3.035262448488326, 'border_count': 59}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:41:37,108] Trial 28 finished with value: 0.24320101679320424 and parameters: {'depth': 7, 'iterations': 260, 'learning_rate': 0.04259244361897381, 'l2_leaf_reg': 3.1613429356666005, 'border_count': 49}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:44:54,402] Trial 29 finished with value: 0.24930704000965503 and parameters: {'depth': 5, 'iterations': 281, 'learning_rate': 0.08699098031416636, 'l2_leaf_reg': 3.489673272950037, 'border_count': 65}. Best is trial 23 with value: 0.2501443568602153.\n",
      "[I 2025-06-10 21:48:13,670] Trial 30 finished with value: 0.25053988013113565 and parameters: {'depth': 5, 'iterations': 288, 'learning_rate': 0.08733638388895791, 'l2_leaf_reg': 3.466353361755627, 'border_count': 75}. Best is trial 30 with value: 0.25053988013113565.\n",
      "[I 2025-06-10 21:51:33,081] Trial 31 finished with value: 0.2497821211037278 and parameters: {'depth': 5, 'iterations': 282, 'learning_rate': 0.08517604795760145, 'l2_leaf_reg': 3.5600745345873688, 'border_count': 74}. Best is trial 30 with value: 0.25053988013113565.\n",
      "[I 2025-06-10 21:54:54,654] Trial 32 finished with value: 0.2493808204415003 and parameters: {'depth': 5, 'iterations': 289, 'learning_rate': 0.08542454335816539, 'l2_leaf_reg': 3.522379563189201, 'border_count': 74}. Best is trial 30 with value: 0.25053988013113565.\n",
      "[I 2025-06-10 21:58:13,918] Trial 33 finished with value: 0.2512377654895433 and parameters: {'depth': 5, 'iterations': 283, 'learning_rate': 0.09859326359218393, 'l2_leaf_reg': 3.6492842109610466, 'border_count': 74}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:01:34,910] Trial 34 finished with value: 0.2504153994616299 and parameters: {'depth': 5, 'iterations': 285, 'learning_rate': 0.09782555596665968, 'l2_leaf_reg': 3.8182312020142737, 'border_count': 74}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:04:50,739] Trial 35 finished with value: 0.24959910016334716 and parameters: {'depth': 4, 'iterations': 300, 'learning_rate': 0.09972601812592734, 'l2_leaf_reg': 3.7661386177256273, 'border_count': 54}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:07:37,928] Trial 36 finished with value: 0.23339903270773893 and parameters: {'depth': 5, 'iterations': 112, 'learning_rate': 0.06122133174224323, 'l2_leaf_reg': 4.446084287118282, 'border_count': 79}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:10:52,429] Trial 37 finished with value: 0.24908555849319708 and parameters: {'depth': 5, 'iterations': 240, 'learning_rate': 0.09354404958014903, 'l2_leaf_reg': 3.335896030389956, 'border_count': 70}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:14:37,393] Trial 38 finished with value: 0.24903218714393544 and parameters: {'depth': 4, 'iterations': 287, 'learning_rate': 0.09978526791442727, 'l2_leaf_reg': 3.8249796041829236, 'border_count': 59}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:18:13,640] Trial 39 finished with value: 0.24394473956348356 and parameters: {'depth': 6, 'iterations': 169, 'learning_rate': 0.07846734354935447, 'l2_leaf_reg': 2.2025504295097553, 'border_count': 79}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:21:59,537] Trial 40 finished with value: 0.24064105020358673 and parameters: {'depth': 5, 'iterations': 252, 'learning_rate': 0.047432006344797044, 'l2_leaf_reg': 2.816658920558437, 'border_count': 68}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:25:51,762] Trial 41 finished with value: 0.24932917437591057 and parameters: {'depth': 5, 'iterations': 283, 'learning_rate': 0.08405483945595608, 'l2_leaf_reg': 3.6933022779370095, 'border_count': 75}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:29:42,740] Trial 42 finished with value: 0.2488526109918988 and parameters: {'depth': 5, 'iterations': 266, 'learning_rate': 0.08632065997017326, 'l2_leaf_reg': 3.3683758805369397, 'border_count': 75}. Best is trial 33 with value: 0.2512377654895433.\n",
      "[I 2025-06-10 22:33:30,771] Trial 43 finished with value: 0.24540960595070382 and parameters: {'depth': 4, 'iterations': 287, 'learning_rate': 0.06519442460933153, 'l2_leaf_reg': 3.5762790847811345, 'border_count': 83}. Best is trial 33 with value: 0.2512377654895433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: No improvement in 10 trials.\n",
      "CatBoost finished in 9373.40 seconds.\n",
      "\n",
      "Best Parameters: {'depth': 5, 'iterations': 283, 'learning_rate': 0.09859326359218393, 'l2_leaf_reg': 3.6492842109610466, 'border_count': 74}\n",
      "Best Average Precision Score (Optuna): 0.2512377654895433\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_68753\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68753_level0_col0\" class=\"col_heading level0 col0\" >Params</th>\n",
       "      <th id=\"T_68753_level0_col1\" class=\"col_heading level0 col1\" >PR-AUC</th>\n",
       "      <th id=\"T_68753_level0_col2\" class=\"col_heading level0 col2\" >PR-AUC (CV)</th>\n",
       "      <th id=\"T_68753_level0_col3\" class=\"col_heading level0 col3\" >ROC-AUC</th>\n",
       "      <th id=\"T_68753_level0_col4\" class=\"col_heading level0 col4\" >F1-Score (Payment Difficulties)</th>\n",
       "      <th id=\"T_68753_level0_col5\" class=\"col_heading level0 col5\" >F1-Score (Other Cases)</th>\n",
       "      <th id=\"T_68753_level0_col6\" class=\"col_heading level0 col6\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68753_level0_row0\" class=\"row_heading level0 row0\" >XGBoost</th>\n",
       "      <td id=\"T_68753_row0_col0\" class=\"data row0 col0\" >{\n",
       "  \"max_depth\": 5,\n",
       "  \"min_child_weight\": 10,\n",
       "  \"n_estimators\": 298,\n",
       "  \"learning_rate\": 0.05113596608549376,\n",
       "  \"subsample\": 0.7482944515367064,\n",
       "  \"colsample_bytree\": 0.8021429739691673,\n",
       "  \"max_delta_step\": 10\n",
       "}</td>\n",
       "      <td id=\"T_68753_row0_col1\" class=\"data row0 col1\" >0.252485</td>\n",
       "      <td id=\"T_68753_row0_col2\" class=\"data row0 col2\" >0.252485</td>\n",
       "      <td id=\"T_68753_row0_col3\" class=\"data row0 col3\" >0.766899</td>\n",
       "      <td id=\"T_68753_row0_col4\" class=\"data row0 col4\" >0.279950</td>\n",
       "      <td id=\"T_68753_row0_col5\" class=\"data row0 col5\" >0.829713</td>\n",
       "      <td id=\"T_68753_row0_col6\" class=\"data row0 col6\" >0.724566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68753_level0_row1\" class=\"row_heading level0 row1\" >LightGBM</th>\n",
       "      <td id=\"T_68753_row1_col0\" class=\"data row1 col0\" >{\n",
       "  \"max_depth\": 6,\n",
       "  \"n_estimators\": 146,\n",
       "  \"learning_rate\": 0.06854658462312682,\n",
       "  \"num_leaves\": 36,\n",
       "  \"min_child_samples\": 49,\n",
       "  \"subsample\": 0.9551128155998938,\n",
       "  \"colsample_bytree\": 0.8916958625383079\n",
       "}</td>\n",
       "      <td id=\"T_68753_row1_col1\" class=\"data row1 col1\" >0.250222</td>\n",
       "      <td id=\"T_68753_row1_col2\" class=\"data row1 col2\" >0.250222</td>\n",
       "      <td id=\"T_68753_row1_col3\" class=\"data row1 col3\" >0.765600</td>\n",
       "      <td id=\"T_68753_row1_col4\" class=\"data row1 col4\" >0.277851</td>\n",
       "      <td id=\"T_68753_row1_col5\" class=\"data row1 col5\" >0.824768</td>\n",
       "      <td id=\"T_68753_row1_col6\" class=\"data row1 col6\" >0.717973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68753_level0_row2\" class=\"row_heading level0 row2\" >CatBoost</th>\n",
       "      <td id=\"T_68753_row2_col0\" class=\"data row2 col0\" >{\n",
       "  \"depth\": 5,\n",
       "  \"iterations\": 283,\n",
       "  \"learning_rate\": 0.09859326359218393,\n",
       "  \"l2_leaf_reg\": 3.6492842109610466,\n",
       "  \"border_count\": 74\n",
       "}</td>\n",
       "      <td id=\"T_68753_row2_col1\" class=\"data row2 col1\" >0.251238</td>\n",
       "      <td id=\"T_68753_row2_col2\" class=\"data row2 col2\" >0.251238</td>\n",
       "      <td id=\"T_68753_row2_col3\" class=\"data row2 col3\" >0.766472</td>\n",
       "      <td id=\"T_68753_row2_col4\" class=\"data row2 col4\" >0.277041</td>\n",
       "      <td id=\"T_68753_row2_col5\" class=\"data row2 col5\" >0.820969</td>\n",
       "      <td id=\"T_68753_row2_col6\" class=\"data row2 col6\" >0.713009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ea7e451820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class EarlyStoppingCallback:\n",
    "    def __init__(self, patience: int = 10):\n",
    "        self.patience = patience\n",
    "        self.best_value = None\n",
    "        self.no_improvement_count = 0\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        if self.best_value is None or study.best_value > self.best_value:\n",
    "            self.best_value = study.best_value\n",
    "            self.no_improvement_count = 0\n",
    "        else:\n",
    "            self.no_improvement_count += 1\n",
    "        if self.no_improvement_count >= self.patience:\n",
    "            print(f\"Early stopping: No improvement in {self.patience} trials.\")\n",
    "            study.stop()\n",
    "\n",
    "\n",
    "objective_funcs = {\n",
    "    \"XGBoost\": objective_xgb,\n",
    "    \"LightGBM\": objective_lgb,\n",
    "    \"CatBoost\": objective_catboost,\n",
    "}\n",
    "\n",
    "for model_name in objective_funcs.keys():\n",
    "    print(f\"Processing {model_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    early_stop = EarlyStoppingCallback(patience=10)\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=model_name)\n",
    "    study.optimize(objective_funcs[model_name], n_trials=50, callbacks=[early_stop])\n",
    "    best_params = study.best_params\n",
    "\n",
    "    if model_name == \"XGBoost\":\n",
    "        best_clf = XGBClassifier(\n",
    "            **best_params,\n",
    "            use_label_encoder=False,\n",
    "            random_state=42,\n",
    "            verbosity=0,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "        )\n",
    "    elif model_name == \"LightGBM\":\n",
    "        best_clf = LGBMClassifier(\n",
    "            **best_params,\n",
    "            random_state=42,\n",
    "            verbosity=-1,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "        )\n",
    "    else:\n",
    "        best_clf = CatBoostClassifier(\n",
    "            **best_params,\n",
    "            verbose=0,\n",
    "            random_seed=42,\n",
    "            auto_class_weights=\"Balanced\",\n",
    "        )\n",
    "\n",
    "    pr_aucs, roc_aucs, f1_1s, f1_0s, accuracies = [], [], [], [], []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"feature_engineering\", feature_engineering),\n",
    "                (\"preprocessor\", preprocessor_no_impute),\n",
    "                (\"classifier\", best_clf),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "        y_pred = pipeline.predict(X_va)\n",
    "\n",
    "        try:\n",
    "            y_pred_proba = pipeline.predict_proba(X_va)[:, 1]\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                decision_scores = pipeline.decision_function(X_va)\n",
    "                denom = decision_scores.max() - decision_scores.min()\n",
    "                y_pred_proba = (\n",
    "                    ((decision_scores - decision_scores.min()) / denom)\n",
    "                    if denom != 0\n",
    "                    else np.zeros_like(y_pred, dtype=float)\n",
    "                )\n",
    "            except:\n",
    "                y_pred_proba = np.zeros_like(y_pred, dtype=float)\n",
    "\n",
    "        pr_aucs.append(average_precision_score(y_va, y_pred_proba))\n",
    "        roc_aucs.append(roc_auc_score(y_va, y_pred_proba))\n",
    "        f1_1s.append(f1_score(y_va, y_pred, pos_label=1, zero_division=0))\n",
    "        f1_0s.append(f1_score(y_va, y_pred, pos_label=0, zero_division=0))\n",
    "        accuracies.append(accuracy_score(y_va, y_pred))\n",
    "\n",
    "    grid_model_results[model_name] = {\n",
    "        \"Best Parameters\": json.dumps(best_params, indent=2),\n",
    "        \"Best Optuna PR-AUC\": study.best_value,\n",
    "        \"Mean PR-AUC\": np.mean(pr_aucs),\n",
    "        \"Mean ROC-AUC\": np.mean(roc_aucs),\n",
    "        \"F1 Score (Payment Difficulties)\": np.mean(f1_1s),\n",
    "        \"F1 Score (Other Cases)\": np.mean(f1_0s),\n",
    "        \"Accuracy\": np.mean(accuracies),\n",
    "    }\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{model_name} finished in {elapsed:.2f} seconds.\\n\")\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Average Precision Score (Optuna):\", study.best_value)\n",
    "    print()\n",
    "\n",
    "    del study, best_clf\n",
    "    gc.collect()\n",
    "\n",
    "df_results = pd.DataFrame(grid_model_results).T.rename(\n",
    "    columns={\n",
    "        \"Best Parameters\": \"Params\",\n",
    "        \"Best Optuna PR-AUC\": \"PR-AUC\",\n",
    "        \"Mean PR-AUC\": \"PR-AUC (CV)\",\n",
    "        \"Mean ROC-AUC\": \"ROC-AUC\",\n",
    "        \"F1 Score (Payment Difficulties)\": \"F1-Score (Payment Difficulties)\",\n",
    "        \"F1 Score (Other Cases)\": \"F1-Score (Other Cases)\",\n",
    "        \"Accuracy\": \"Accuracy\",\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    display(df_results.style.background_gradient(cmap=\"Blues\"))\n",
    "except ImportError:\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eca487",
   "metadata": {},
   "source": [
    "After tuning we see that:\n",
    "* PR-AUC (CV) is similar to all models, with highest being XGBoost (25.25%), but all PR-AUC are around 25%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
